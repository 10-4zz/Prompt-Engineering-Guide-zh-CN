# 提示词（prompt）工程指南：提示介绍

提示工程是一种相对较新的学科，专门用于开发和优化提示，以高效地使用语言模型（LM）来处理各种应用和研究主题。提示工程技能有助于更好地理解大型语言模型（LLMs）的能力和局限性。研究人员使用提示工程来提高LLMs在各种常见和复杂任务上的容量，例如问题解答和算术推理。开发人员使用提示工程来设计与LLMs和其他工具接口的强大而有效的提示技术。

本指南介绍了标准提示的基础知识，以提供如何使用提示与大型语言模型（LLMs）进行交互和指导的大致概念。

除非另有说明，否则所有示例均已经过“text-davinci-003”（使用OpenAI的playground）测试。它使用默认配置，例如`temperature=0.7`和`top-p=1`。

主题:

<!-- TOC -->

- [提示词（prompt）工程指南：提示介绍](#%E6%8F%90%E7%A4%BA%E8%AF%8Dprompt%E5%B7%A5%E7%A8%8B%E6%8C%87%E5%8D%97%E6%8F%90%E7%A4%BA%E4%BB%8B%E7%BB%8D)
    - [基础提示](#%E5%9F%BA%E7%A1%80%E6%8F%90%E7%A4%BA)
    - [关于LLM设置的说明](#%E5%85%B3%E4%BA%8Ellm%E8%AE%BE%E7%BD%AE%E7%9A%84%E8%AF%B4%E6%98%8E)
    - [标准提示](#%E6%A0%87%E5%87%86%E6%8F%90%E7%A4%BA)
    - [设计提示的一般提示](#%E8%AE%BE%E8%AE%A1%E6%8F%90%E7%A4%BA%E7%9A%84%E4%B8%80%E8%88%AC%E6%8F%90%E7%A4%BA)
        - [开始简单](#%E5%BC%80%E5%A7%8B%E7%AE%80%E5%8D%95)
        - [指令](#%E6%8C%87%E4%BB%A4)
        - [具体性](#%E5%85%B7%E4%BD%93%E6%80%A7)
        - [避免不精确。](#%E9%81%BF%E5%85%8D%E4%B8%8D%E7%B2%BE%E7%A1%AE)
        - [做还是不做？](#%E5%81%9A%E8%BF%98%E6%98%AF%E4%B8%8D%E5%81%9A)

<!-- /TOC -->

---

## 基础提示

您可以通过提示实现很多功能，但结果的质量取决于您提供多少信息。提示可以包含诸如传递给模型的`instruction`或`question`等信息，并包括其他细节，例如`inputs`或`examples`。

这是一个简单提示的基本示例：

*提示*
```
The sky is
```

*输出：*
```
蓝色的

在晴朗的日子里，天空是蓝色的。 在多云的日子里，天空可能是灰色或白色的。
```

正如您所见，语言模型输出了字符串连续体的延续部分，使之与上下文“The sky is”具有一定的意义。输出可能出乎意料或与我们要完成的任务相距甚远。

这个基本示例也凸显了提供更多上下文或指令有多么必要以便更加精确地达到我们的目的。

让我们尝试改进一下：*提示：*
```
完成下面这个句子：

天空
```

*输出：*

```
今天好美啊。
```

这样好一些了吗？我们告诉模型要完成这个句子，所以结果看起来更好，它完全按照我们的要求执行了任务，这种设计最优提示以指导模型完成任务的方法被称为**提示工程**。

上面的例子是对当前LLM的基本说明。 当前的LLMs能够执行各种高级任务，包括文本摘要、数学推理和代码生成。

---
## 关于LLM设置的说明

在使用提示时，您将通过API或直接与LLM进行交互。您可以配置一些参数以获得不同提示的结果。

**温度** - 简而言之，温度越低，结果就越确定，因为始终选择最有可能的下一个标记。增加温度可能会导致更多的随机性，从而鼓励更多元化或创造性的输出。实际应用中，我们可能希望对基于事实的QA使用较低的温度来鼓励更加客观和简洁的回答。 对于像诗歌生成或其他创意任务，增加温度可能是有益的。

**Top_p** - 类似地，通过称为nucleus采样的带有温度的采样技术，可以控制模型在生成响应时的确定性。如果您正在寻找准确和事实的答案，请将其保持在低值。如果你正在寻找更多元化的回答，请将其增加到较高的值。

通常的建议是只更改其中一个。

在开始一些基本的示例之前，请记住，您的结果可能取决于您使用的LLM版本。

---
## 标准提示

我们在上面尝试了一个非常简单的提示。标准提示的格式如下：

```
<问题>?
```

这可以格式化为QA格式，这在许多QA数据集中是标准格式，如下：

```
Q：<问题>？
A：
```

鉴于上述标准格式，一种流行且有效的提示技术称为few-shot prompting，我们在其中提供范例。Few-shot prompts可以格式化如下：

```
<问题>？
<答案>

<问题>？
<答案>

<问题>？
<答案>

<问题>？

```


而它的QA格式版本看起来像这样：

```
Q：<问题>？
A：<答案>

Q：<问题>？
A：<答案>

Q：<问题>？
A：<答案>

Q：<问题>？
A：
```

请记住，不需要使用QA格式。格式取决于手头的任务。例如，您可以执行简单的分类任务并提供演示任务的范例，如下所示：

*提示：*
```
这真棒！ // 积极
这很糟糕！ // 消极
哇，那部电影太酷了！ // 积极
这是一个多么糟糕的节目！ //
```

*输出：*
```
消极
```

Few-shot prompts可以实现上下文学习，这是语言模型在只有少数例子的情况下学习任务的能力。在即将推出的指南中，我们将看到更多此类操作。

---
##提示元素

随着我们涵盖越来越多的提示工程示例和应用程序，您会注意到某些元素构成了提示。

提示可以包含以下任何组件：

**说明**-要求模型执行的具体任务或说明

**上下文**-可能涉及外部信息或额外上下文，可以使模型更好地响应

**输入数据**-我们感兴趣的输入或问题

**输出指示器**-指示输出的类型或格式。

并非所有组件都需要进行提示，格式取决于手头的任务。在即将推出的指南中，我们将介绍更多具体例子。

---
## 设计提示的一般提示

以下是设计提示时需要牢记的一些提示：

### 开始简单

作为您开始设计提示的起点，您应该牢记它是一个迭代的过程，需要大量的实验来达到最佳的结果。使用像 OpenAI 或 Cohere 这样的简单播放器是一个不错的起点。

您可以从简单的提示开始，随着您的目标变得更好，不断添加更多的元素和背景。在此过程中对您的提示进行版本控制非常重要。当我们阅读本指南时，您将看到许多示例，其中详细、简洁和简明的提示通常会给您带来更好的结果。

当您有涉及许多不同子任务的大任务时，您可以尝试将任务分解为更简单的子任务，并随着获得更好的结果而不断添加。这避免了在提示设计过程中开始时添加过多的复杂性。

### 指令

您可以使用命令来指示模型您想要实现的内容，例如“写入”、“分类”、“总结”、“翻译”、“排序”等，从而为各种简单任务设计有效的提示。

请记住，您还需要进行大量实验以了解最佳的方法。尝试不同的指令与不同的关键字、上下文和数据，并观察哪种方法最适合您特定的用例和任务。通常，上下文与您要执行的任务相关性越强，越具体和相关，结果越好。我们将在即将推出的指南中讨论采样和添加更多上下文的重要性。

其他人建议指令放在提示的开头。还建议使用一些清晰的分隔符，如“###”来分隔指令和上下文。

例如：

*提示：*

```
### 指令 ###
将下面的文本翻译成西班牙语：

文本：“你好！”
```

*输出：*
```
¡Hola!
```

### 具体性

格式：仅返回已翻译的内容，不包括原文。请具体说明您想要模型执行的指令和任务。提示越描述详细，结果就会越好。当您需要的是特定的生成结果或风格时，这一点尤为重要。没有特定的令牌或关键字能够提供更好的结果。拥有良好的格式和详细的提示更为重要。在提示中提供例子非常有助于在特定格式下获得所需的输出。

在设计提示时，您还应考虑提示的长度，因为有关长度的限制。需要考虑精确定义和详细程度。过多不必要的细节并不是一个好的方式。细节应该是相关的，并有助于解决手头的任务。这是您需要进行大量实验的事情。我们鼓励大量实验和迭代，以优化提示以适应您的应用。

例如，让我们尝试从文本中提取特定信息的简单提示。

*提示：*
```
从以下文本中提取地名。

期望的格式：
地点：<逗号分隔公司名称的列表>

输入："Although these developments are encouraging to researchers, much is still a mystery. “We often have a black box between the brain and the effect we see in the periphery,” says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. “If we want to use it in the therapeutic context, we need to understand the mechanism."
```
*输出:*
```
地点：Champalimaud Centre for the Unknown、Lisbon
```

输入文本来源于[这篇Nature文章](https://www.nature.com/articles/d41586-023-00509-z)。

### 避免不精确。

给出了有关详细说明和改进格式的提示之后，很容易陷入关于提示过于聪明并可能创建不准确的描述的陷阱。通常更好的方法是具体而直接。这里的类比与有效的沟通非常相似——越直接，信息传递就越有效。

例如，您可能有兴趣了解提示工程的概念。您可能尝试这样做：

```
解释提示工程的概念。保持解释简短，只有几个句子，并且不要过于冗长。
```

从上面的提示中不清楚要使用多少句子和什么样的风格。您可能仍然可以通过以上提示获得不错的回应，但更好的提示是非常具体，简洁明了，直指要点的提示。例如：

```
使用2-3句话向高中生解释提示工程的概念。
```

### 做还是不做？

设计提示时的另一个常见提示是避免说出不要做什么，而要说出相应的做法。这样可以更具体，并侧重于细节，这些细节可以引导模型产生良好的响应。

以下是电影推荐聊天机器人在我编写的指示中失败的一个例子，因为我关注了不要做什么。 

*提示：*
```
以下是向顾客推荐电影的代理。不要问利益。不要问个人信息。

顾客：请根据我的兴趣推荐电影。
代理：
```

*输出：*

```
当然，我可以根据您的兴趣推荐电影。您想看哪种类型的电影？您喜欢动作片、喜剧片、爱情片还是其他类型的电影？
```

以下是一个更好的提示：

*提示：*

```
以下是向客户推荐电影的代理。代理应该从全球热门电影中推荐电影给客户。它不应该询问用户的偏好并避免询问个人信息。如果代理没有电影可以推荐，它应该回复“对不起，今天找不到电影可以推荐。”。

客户：请根据我的兴趣推荐一部电影。
代理：
```

*输出：*
```
很抱歉，我没有关于您兴趣的信息。然而，这是目前全球热门电影列表：[电影列表]。希望您能喜欢其中某个！
```

上述示例部分摘自“OpenAI API提示工程最佳实践文章”。

---
[下一章节（基本提示）](./prompts-basic-usage.md)。